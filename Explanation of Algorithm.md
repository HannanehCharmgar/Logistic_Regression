# الگوریتم رگرسیون لجستیک (Logistic Regression)


---

## رگرسیون لجستیک چیست؟

رگرسیون لجستیک (Logistic Regression) یک الگوریتم **یادگیری نظارت‌شده (Supervised Learning)** است که برای **مسائل طبقه‌بندی دودویی (Binary Classification)** استفاده می‌شود.  
هدف این الگوریتم، پیش‌بینی **احتمال تعلق یک نمونه به کلاس مثبت (Class 1)** است.

برخلاف رگرسیون خطی که خروجی عددی پیوسته تولید می‌کند،  
رگرسیون لجستیک خروجی خود را به صورت **احتمال بین 0 و 1** ارائه می‌دهد و سپس با استفاده از یک آستانه (Threshold)، تصمیم نهایی طبقه‌بندی را می‌گیرد.

ویژگی مهم این الگوریتم:
- ساده
- قابل تفسیر
- سریع
- بسیار پرکاربرد در مسائل پزشکی، مالی و تصمیم‌گیری‌های باینری

---

## مرحله ۱: تعریف مسئله (Problem Definition)

ما با یک مسئله **طبقه‌بندی دودویی** طرف هستیم.

مثال:
- آیا بیمار دیابت دارد؟ → 1  
- یا دیابت ندارد؟ → 0  

خروجی فقط دو مقدار ممکن دارد و پیوسته نیست.

---

## مرحله ۲: داده‌ها و Featureها

### ویژگی (feature) چیست؟

یعنی هر اطلاعاتی که از یک داده می‌گیریم تا مدل باهاش تصمیم بگیره.

مثال در دیتاست دیابت:
- Glucose
- BMI
- Age
- BloodPressure

هر سطر داده نشان‌دهنده یک فرد و هر ستون یک Feature است.

---

## مرحله ۳: ترکیب خطی Featureها (Linear Combination)

در ابتدا، رگرسیون لجستیک مانند رگرسیون خطی عمل می‌کندم:

z = w1x1 + w2x2 + ... + wnxn + b

که در آن:
- متغیر x = ویژگی ها ( features ) 
- متغیر w = اهمیت feature ها ( وزن ها) 
- متغیرb = بایاس مدل است.

خروجی این مرحله می‌تواند هر عددی باشد (منفی یا مثبت).

---

## مرحله ۴: مشکل خروجی خطی

مقادیر خطی مانند:
- z = 6.4
- z = -3.2

ما با عدد 6.4 نمیتوانیم متوجه شیم فرد دیابت دارد یا خیر و قابل تفسیر به عنوان «احتمال» نیستند چون ما نیاز داریم خروجی مدل به عددی بین 0 و 1 تبدیل شود.

---

## مرحله ۵: تابع سیگموئید (Sigmoid Function)

تابع سیگموئید هسته اصلی رگرسیون لجستیک است.

فرمول:
σ(z) = 1 / (1 + e^(-z))

این تابع هر عددی را به بازه [0, 1] نگاشت می‌کند.

<img width="485" height="323" alt="1694183259537" src="https://github.com/user-attachments/assets/c79c04c5-3662-4ddb-b0b5-7b0bfa5cf3f3" />

- **محور افقی (x-axis):**  
  مقدار z که از رابطه زیر به‌دست می‌آید:

  z = w₁x₁ + w₂x₂ + ... + wₙxₙ + b

- **محور عمودی (y-axis):**  
  مقدار σ(z) که عددی بین 0 و 1 است و به‌عنوان احتمال تفسیر می‌شود
  
| مقدار z | خروجی σ(z) | تفسیر |
|------|-----------|-------|
| z ≪ 0 | نزدیک 0 | احتمال بسیار کم برای کلاس مثبت |
| z = 0 | 0.5 | مرز تصمیم‌گیری |
| z ≫ 0 | نزدیک 1 | احتمال بسیار زیاد برای کلاس مثبت |
---

## مرحله ۶: تفسیر خروجی مدل

خروجی مدل اکنون یک **احتمال** است.

مثال:
P(y=1) = 0.78

یعنی:
این فرد با احتمال 78٪ به کلاس مثبت (مثلاً بیمار) تعلق دارد.

---

## مرحله ۷: آستانه تصمیم (Decision Threshold)

برای تبدیل احتمال به کلاس نهایی:

اگر p ≥ 0.5 → کلاس 1  
اگر p < 0.5 → کلاس 0  

آستانه 0.5 رایج است، اما قابل تغییر است.


<img width="700" height="300" alt="image" src="https://github.com/user-attachments/assets/f2cf8cce-456f-45ae-80d6-2130f4043fd6" />


در پزشکی معمولاً آستانه پایین‌تر انتخاب می‌شود تا بیماران بیشتری شناسایی شوند.

---

## مرحله ۸: تابع هزینه (Log Loss)

برای یادگیری مدل از تابع هزینه Cross-Entropy استفاده می‌شود:

Loss = -[y log(p) + (1-y) log(1-p)]

ویژگی مهم:
- پیش‌بینی اشتباه با اطمینان بالا → جریمه سنگین
- پیش‌بینی درست → جریمه کم

<img width="700" height="350" alt="image" src="https://github.com/user-attachments/assets/328cf481-6a81-4b18-8272-cfb9e0ae042a" />

این نمودار نشان‌دهنده **تابع هزینه (Loss) رگرسیون لجستیک** برای یک نمونه است. توضیح مختصرش به صورت زیر است:

* محور افقی `h(x)` مقدار پیش‌بینی مدل (احتمال برچسب ۱) را نشان می‌دهد.
* محور عمودی **Loss** میزان خطا یا هزینه پیش‌بینی را نمایش می‌دهد.
* خط قرمز: `log(h(x))-` که وقتی نمونه واقعی برچسب ۱ دارد استفاده می‌شود.
  * اگر `h(x)` نزدیک ۰ باشد، خطا بسیار بزرگ است.
  * اگر `h(x)` نزدیک ۱ باشد، خطا نزدیک ۰ است.
* خط سیاه: `log(1-h(x))-` که وقتی نمونه واقعی برچسب ۰ دارد استفاده می‌شود.
  * اگر `h(x)` نزدیک ۱ باشد، خطا زیاد است.
  * اگر `h(x)` نزدیک ۰ باشد، خطا نزدیک ۰ است.

**برداشت کلی:**  
تابع هزینه رگرسیون لجستیک جریمه شدیدی برای پیش‌بینی‌های اشتباه با اطمینان بالا اعمال می‌کند و پیش‌بینی‌های درست را با خطای کم تشویق می‌کند. این باعث می‌شود گرادیان نزولی هنگام آموزش مدل عملکرد خوبی داشته باشد.

---

## مرحله ۹: بهینه‌سازی (Optimization)

مدل با استفاده از روش‌هایی مانند:
- Gradient Descent
- Solverهای عددی

وزن‌ها (w) و بایاس (b) را طوری تنظیم می‌کند که تابع هزینه کمینه شود.

---

## مرحله ۱۰: ماتریس سردرگمی (Confusion Matrix)

پس از آموزش، عملکرد مدل بررسی می‌شود.

| وضعیت واقعی | پیش‌بینی مدل |
|------------|-------------|
| TP | بیمار → بیمار |
| TN | سالم → سالم |
| FP | سالم → بیمار |
| FN | بیمار → سالم |


<img width="700" height="350" alt="image" src="https://github.com/user-attachments/assets/e61c2513-0ee3-46d8-a70a-6a46c9e5800b" />


طبق این ماتریس میتوانیم عملکرد مدل را ارزیابی کنیم:



###  Accuracy (دقت کلی)
$\[
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
\]$

###  Precision (دقت پیش‌بینی‌های مثبت)
$\[
\text{Precision} = \frac{TP}{TP + FP}
\]$

###  Recall / Sensitivity (توانایی یافتن بیماران واقعی)
$\[
\text{Recall} = \frac{TP}{TP + FN}
\]$

###  F1-Score (تعادل Precision و Recall)
$\[
F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
\]$


در پزشکی، FN خطرناک‌ترین خطاست.

---


## جمع‌بندی نهایی

رگرسیون لجستیک:
- ویژگی( feature ) ها را وزن دهی میکند.
- خروجی خطی می‌سازد
- با سیگموئید → احتمال تولید می‌کند
- با آستانه → تصمیم نهایی می‌گیرد


**رگرسیون لجستیک = تبدیل عدد به احتمال و سپس تصمیم منطقی**
